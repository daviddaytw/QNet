{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path += ['../']\n",
    "from utils.lr_finder import LRFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake Model for Quick POC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path += ['../']\n",
    "from utils.lr_finder import LRFinder\n",
    "\n",
    "np.random.seed(43)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "epoch = 5\n",
    "batch_size = 32\n",
    "sample_size = 50\n",
    "train_data = tf.data.Dataset.from_tensor_slices((np.zeros((sample_size, batch_size, 10, 3)),np.random.rand(sample_size, batch_size, 1)))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((np.zeros((sample_size, batch_size, 10, 3)), np.random.rand(sample_size, batch_size, 1)))\n",
    "\n",
    "callbacks = [LRFinder(train_data, batch_size, window_size=4, max_steps=400, filename='logs/lr_finder')]\n",
    "lr_decayed_fn = tf.keras.optimizers.schedules.CosineDecay((4,400), epoch * len(train_data), alpha=1e-2)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr_decayed_fn, beta_1=0.9, beta_2=0.98, epsilon=1e-09)\n",
    "model.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "model.fit(train_data, validation_data=test_data, batch_size=batch_size, epochs=5, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Model for Validation and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path += ['../']\n",
    "from utils.lr_finder import LRFinder\n",
    "\n",
    "import os, json, time\n",
    "from datasets import get_dataset\n",
    "from trainers import get_trainer\n",
    "\n",
    "def save_log(history, val_metric: str=None):\n",
    "    logs = { 'history': history }\n",
    "\n",
    "    if val_metric != None:\n",
    "        logs['best_acc'] = max(history[val_metric])\n",
    "        print('Best score: ', logs['best_acc'])\n",
    "\n",
    "    logfile_name = f'logs/qnet-{int(time.time())}.json'\n",
    "    os.makedirs(os.path.dirname(logfile_name), exist_ok=True)\n",
    "    with open(logfile_name, 'w') as f:\n",
    "        json.dump(logs, f, indent=4)\n",
    "    print('Log file saved at: ', logfile_name)\n",
    "\n",
    "class Args:\n",
    "    lr = 3e-4 * 128\n",
    "    batch_size = 128\n",
    "    seq_len = 8\n",
    "    epochs = 5\n",
    "    model = 'fnet'\n",
    "    embed_size = 16\n",
    "    num_blocks = 1\n",
    "    qnet_depth = 1\n",
    "    lr_finder = [4,400,'logs/lr_finder']\n",
    "    dataset = 'msra'\n",
    "    # dataset = 'colbert'\n",
    "    # dataset = 'rentrunway'\n",
    "    # dataset = 'msra'\n",
    "\n",
    "args = Args()\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")\n",
    "\n",
    "dataset = get_dataset(args.dataset)\n",
    "trainer = get_trainer(dataset.getTask())\n",
    "\n",
    "fitting = trainer.train(args, dataset)\n",
    "\n",
    "if dataset.getTask() == 'classification':\n",
    "    if dataset.getOutputSize() > 2:\n",
    "        save_log(fitting.history, 'val_categorical_accuracy')\n",
    "    else:\n",
    "        save_log(fitting.history, 'val_binary_accuracy')\n",
    "else:\n",
    "    save_log(fitting.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('QNet-80tnyBMQ')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "194ce798efaa7768c776effb78dc6a27ac2f4434f28b58117e0469f54c5184ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
